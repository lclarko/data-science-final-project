{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Complete Twitter Dataset\n",
    "\n",
    "* The purpose of this notebook is to explore the full dataset of 400k tweets relating to #bcpoli\n",
    "* Tweet created dates range from August 14, 2020 to November 19, 2020\n",
    "* Columns not required for analysis will be dropped here.\n",
    " * The remaining data will be exported for preprocessing in \"classify_unlabelled_tweets.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/lclark/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '/Users/lclark/data_bootcamp/data-science-final-project/scripts/')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdpipe as pdp\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from IPython.display import JSON\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Pandas Display Settings, if you wish\n",
    "\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "#pd.set_option(\"display.max_columns\", 30)\n",
    "\n",
    "# Import custom functions \n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ~398K Tweets from August 14th, 2020 - November 19th, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 19s, sys: 3min 14s, total: 5min 34s\n",
      "Wall time: 7min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_json('/Volumes/My Passport/Tweets/bcpoli_400k_extended.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 384221 entries, 0 to 384220\n",
      "Data columns (total 31 columns):\n",
      " #   Column                     Non-Null Count   Dtype              \n",
      "---  ------                     --------------   -----              \n",
      " 0   created_at                 384221 non-null  datetime64[ns, UTC]\n",
      " 1   id                         384221 non-null  int64              \n",
      " 2   id_str                     384221 non-null  int64              \n",
      " 3   full_text                  384221 non-null  object             \n",
      " 4   truncated                  384221 non-null  bool               \n",
      " 5   display_text_range         384221 non-null  object             \n",
      " 6   entities                   384221 non-null  object             \n",
      " 7   source                     384221 non-null  object             \n",
      " 8   in_reply_to_status_id      26530 non-null   float64            \n",
      " 9   in_reply_to_status_id_str  26530 non-null   float64            \n",
      " 10  in_reply_to_user_id        29115 non-null   float64            \n",
      " 11  in_reply_to_user_id_str    29115 non-null   float64            \n",
      " 12  in_reply_to_screen_name    29115 non-null   object             \n",
      " 13  user                       384221 non-null  object             \n",
      " 14  geo                        35 non-null      object             \n",
      " 15  coordinates                35 non-null      object             \n",
      " 16  place                      3695 non-null    object             \n",
      " 17  contributors               0 non-null       float64            \n",
      " 18  retweeted_status           282507 non-null  object             \n",
      " 19  is_quote_status            384221 non-null  bool               \n",
      " 20  quoted_status_id           87145 non-null   float64            \n",
      " 21  quoted_status_id_str       87145 non-null   float64            \n",
      " 22  quoted_status_permalink    87145 non-null   object             \n",
      " 23  retweet_count              384221 non-null  int64              \n",
      " 24  favorite_count             384221 non-null  int64              \n",
      " 25  favorited                  384221 non-null  bool               \n",
      " 26  retweeted                  384221 non-null  bool               \n",
      " 27  lang                       384221 non-null  object             \n",
      " 28  quoted_status              26756 non-null   object             \n",
      " 29  possibly_sensitive         85009 non-null   float64            \n",
      " 30  extended_entities          22231 non-null   object             \n",
      "dtypes: bool(4), datetime64[ns, UTC](1), float64(8), int64(4), object(14)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage='deep')\n",
    "# It appears that over ten thousand. tweets have been deleted since August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~//data_bootcamp/data-science-final-project/scripts/functions.py\u001b[0m in \u001b[0;36mreplace_retweet_text\u001b[0;34m(df, check_col, rt_col)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreplace_retweet_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheck_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'full_text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrt_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rt_full_text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrt_regex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrt_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'str'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_bootcamp/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_bootcamp/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_align_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0minfo_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minfo_axis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_bootcamp/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_align_series\u001b[0;34m(self, indexer, ser, multiindex_indexer)\u001b[0m\n\u001b[1;32m   1931\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1933\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m                 \u001b[0;31m# 2 dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_bootcamp/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m   4409\u001b[0m     )\n\u001b[1;32m   4410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4413\u001b[0m     def drop(\n",
      "\u001b[0;32m/anaconda3/envs/data_bootcamp/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4460\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4461\u001b[0m         return self._reindex_axes(\n\u001b[0;32m-> 4462\u001b[0;31m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4463\u001b[0m         ).__finalize__(self, method=\"reindex\")\n\u001b[1;32m   4464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_bootcamp/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   4483\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4484\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4485\u001b[0;31m                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4486\u001b[0m             )\n\u001b[1;32m   4487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_bootcamp/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4528\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4529\u001b[0m                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4530\u001b[0;31m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4531\u001b[0m             )\n\u001b[1;32m   4532\u001b[0m             \u001b[0;31m# If we've made a copy once, no need to make another one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_bootcamp/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/data_bootcamp/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   3287\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Make copy of imported data and set index to unique tweet ID\n",
    "raw = df.copy()\n",
    "raw = raw[~raw.index.duplicated(keep='first')]\n",
    "# Filter out columns\n",
    "raw = col_filter(raw)\n",
    "# Extract features from user column dict with .get\n",
    "raw = extract_username(raw)\n",
    "# Create is_retweet column\n",
    "raw['is_retweet'] = raw['full_text'].apply(is_retweet) # This was originally for pdpipe and could be rewrittten\n",
    "# Create new col \"rt_full_text\" from dict column \"retweet_status\"\n",
    "raw = extract_full_text(raw)\n",
    "# Repalce truncated retweet full_text\n",
    "raw = replace_retweet_text(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 276 ms, sys: 30 ms, total: 306 ms\n",
      "Wall time: 307 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>vader_text</th>\n",
       "      <th>no_hashtags</th>\n",
       "      <th>full_clean</th>\n",
       "      <th>covid_mention</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_name</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1306334233523179520</th>\n",
       "      <td>2020-09-16 20:48:46+00:00</td>\n",
       "      <td>In the summer Boot destroyed all of the bandan...</td>\n",
       "      <td>In the summer Boot destroyed all of the bandan...</td>\n",
       "      <td>[summer, boot, destroyed, bandannas, confedera...</td>\n",
       "      <td>[summer, boot, destroyed, bandannas, confedera...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7adamandrews</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327113858251571200</th>\n",
       "      <td>2020-11-13 04:59:35+00:00</td>\n",
       "      <td>All that money they're blowing on the #SiteC d...</td>\n",
       "      <td>All that money they're blowing on the #SiteC d...</td>\n",
       "      <td>[money, theyre, blowing, dam, yeah, gon, na, pay]</td>\n",
       "      <td>[money, theyre, blowing, sitec, dam, yeah, gon...</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>koenigcomm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318789405692239872</th>\n",
       "      <td>2020-10-21 05:41:10+00:00</td>\n",
       "      <td>Douglas Todd: Finally, the party's over for no...</td>\n",
       "      <td>Douglas Todd: Finally, the party's over for no...</td>\n",
       "      <td>[douglas, todd, finally, partys, nolimit, poli...</td>\n",
       "      <td>[douglas, todd, finally, partys, nolimit, poli...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>suestroud</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318947440611844096</th>\n",
       "      <td>2020-10-21 16:09:09+00:00</td>\n",
       "      <td>In BC its #frackingLNG #deforestation #sitec i...</td>\n",
       "      <td>In BC its #frackingLNG #deforestation #sitec i...</td>\n",
       "      <td>[bc, industries, pls, sake, amp, vote, riding]</td>\n",
       "      <td>[bc, frackinglng, deforestation, sitec, indust...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>cindian1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309232401504063488</th>\n",
       "      <td>2020-09-24 20:45:03+00:00</td>\n",
       "      <td>I am so excited and so honoured to be the @bcn...</td>\n",
       "      <td>I am so excited and so honoured to be the @bcn...</td>\n",
       "      <td>[excited, honoured, candidate, victoriabeacon,...</td>\n",
       "      <td>[excited, honoured, candidate, victoriabeacon,...</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>briancampbellC1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   created_at  \\\n",
       "id_str                                          \n",
       "1306334233523179520 2020-09-16 20:48:46+00:00   \n",
       "1327113858251571200 2020-11-13 04:59:35+00:00   \n",
       "1318789405692239872 2020-10-21 05:41:10+00:00   \n",
       "1318947440611844096 2020-10-21 16:09:09+00:00   \n",
       "1309232401504063488 2020-09-24 20:45:03+00:00   \n",
       "\n",
       "                                                             full_text  \\\n",
       "id_str                                                                   \n",
       "1306334233523179520  In the summer Boot destroyed all of the bandan...   \n",
       "1327113858251571200  All that money they're blowing on the #SiteC d...   \n",
       "1318789405692239872  Douglas Todd: Finally, the party's over for no...   \n",
       "1318947440611844096  In BC its #frackingLNG #deforestation #sitec i...   \n",
       "1309232401504063488  I am so excited and so honoured to be the @bcn...   \n",
       "\n",
       "                                                            vader_text  \\\n",
       "id_str                                                                   \n",
       "1306334233523179520  In the summer Boot destroyed all of the bandan...   \n",
       "1327113858251571200  All that money they're blowing on the #SiteC d...   \n",
       "1318789405692239872  Douglas Todd: Finally, the party's over for no...   \n",
       "1318947440611844096  In BC its #frackingLNG #deforestation #sitec i...   \n",
       "1309232401504063488  I am so excited and so honoured to be the @bcn...   \n",
       "\n",
       "                                                           no_hashtags  \\\n",
       "id_str                                                                   \n",
       "1306334233523179520  [summer, boot, destroyed, bandannas, confedera...   \n",
       "1327113858251571200  [money, theyre, blowing, dam, yeah, gon, na, pay]   \n",
       "1318789405692239872  [douglas, todd, finally, partys, nolimit, poli...   \n",
       "1318947440611844096     [bc, industries, pls, sake, amp, vote, riding]   \n",
       "1309232401504063488  [excited, honoured, candidate, victoriabeacon,...   \n",
       "\n",
       "                                                            full_clean  \\\n",
       "id_str                                                                   \n",
       "1306334233523179520  [summer, boot, destroyed, bandannas, confedera...   \n",
       "1327113858251571200  [money, theyre, blowing, sitec, dam, yeah, gon...   \n",
       "1318789405692239872  [douglas, todd, finally, partys, nolimit, poli...   \n",
       "1318947440611844096  [bc, frackinglng, deforestation, sitec, indust...   \n",
       "1309232401504063488  [excited, honoured, candidate, victoriabeacon,...   \n",
       "\n",
       "                     covid_mention  retweet_count        user_name  is_retweet  \n",
       "id_str                                                                          \n",
       "1306334233523179520              0              8     7adamandrews           1  \n",
       "1327113858251571200              0             54       koenigcomm           1  \n",
       "1318789405692239872              0              4        suestroud           1  \n",
       "1318947440611844096              0              1         cindian1           0  \n",
       "1309232401504063488              0             44  briancampbellC1           1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Pandas Processing Pipeline\n",
    "\n",
    "pipeline = pdp.ColDrop('user')\n",
    "pipeline+= pdp.ApplyByCols('full_text', lower_case, 'full_lower', drop=False)\n",
    "pipeline+= pdp.ApplyByCols('full_lower', covid_mention, 'covid_mention', drop=True)\n",
    "pipeline+= pdp.ApplyByCols('full_text', preprocess, 'full_clean', drop=False)\n",
    "pipeline+= pdp.ApplyByCols('full_text', (lambda x: preprocess(x, hashtags=True)), 'no_hashtags', drop=False) \n",
    "pipeline+= pdp.ApplyByCols('full_text', vader_preprocess, 'vader_text', drop=False)\n",
    "pipeline+= pdp.ColDrop('retweeted_status') \n",
    "pipeline+= pdp.ColDrop('rt_full_text')\n",
    "raw = pipeline(raw)\n",
    "raw.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.04 s, sys: 98.2 ms, total: 2.14 s\n",
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Pandas Processing Pipeline\n",
    "\n",
    "pipeline = pdp.ColDrop('user')\n",
    "pipeline+= pdp.ApplyByCols('full_text', lower_case, 'full_lower', drop=False)\n",
    "pipeline+= pdp.ApplyByCols('full_lower', covid_mention, 'covid_mention', drop=True)\n",
    "pipeline+= pdp.ApplyByCols('full_text', is_retweet, 'is_retweet', drop=False)\n",
    "pipeline+= pdp.ApplyByCols('full_text', preprocess, 'full_clean', drop=False)\n",
    "pipeline+= pdp.ApplyByCols('full_text', (lambda x: preprocess(x, hashtags=True)), 'no_hashtags', drop=False) \n",
    "raw = pipeline(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new DataFrames separate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the updated DataFrame of tweet.\n",
    "# df_filtered_tweets_master has been processed identically as above\n",
    "# df_filtered_tweets_master will always be the most current DataFrame\n",
    "# Reproduciibility still possible with /data/tweet_ids.txt. It is updated with the tweet_ids from df_filtered_tweets_master\n",
    "raw = pd.read_pickle('~/data_bootcamp/data-science-final-project/data/df_filtered_tweets_master.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 106077 entries, 1294232573636304896 to 1329212767929200640\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype              \n",
      "---  ------         --------------   -----              \n",
      " 0   created_at     106077 non-null  datetime64[ns, UTC]\n",
      " 1   full_text      106077 non-null  object             \n",
      " 2   vader_text     106077 non-null  object             \n",
      " 3   no_hashtags    106077 non-null  object             \n",
      " 4   full_clean     106077 non-null  object             \n",
      " 5   covid_mention  106077 non-null  int64              \n",
      " 6   retweet_count  106077 non-null  int64              \n",
      " 7   user_name      106077 non-null  object             \n",
      " 8   is_retweet     106077 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(3), object(5)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Create new DataFrame of only original tweets\n",
    "\n",
    "df_no_rt = raw[raw['is_retweet'] == 0]\n",
    "df_no_rt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 75462 entries, 1294233211262783488 to 1329212785058836480\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   created_at     75462 non-null  datetime64[ns, UTC]\n",
      " 1   full_text      75462 non-null  object             \n",
      " 2   vader_text     75462 non-null  object             \n",
      " 3   no_hashtags    75462 non-null  object             \n",
      " 4   full_clean     75462 non-null  object             \n",
      " 5   covid_mention  75462 non-null  int64              \n",
      " 6   retweet_count  75462 non-null  int64              \n",
      " 7   user_name      75462 non-null  object             \n",
      " 8   is_retweet     75462 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(3), object(5)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Create a new DatFrame with only original non-covid tweets\n",
    "# This will be used to guage the covids impact on sentiment\n",
    "\n",
    "df_no_rt_no_covid = df_no_rt[df_no_rt['covid_mention'] == 0]\n",
    "df_no_rt_no_covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30615 entries, 1294232573636304896 to 1329212767929200640\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   created_at     30615 non-null  datetime64[ns, UTC]\n",
      " 1   full_text      30615 non-null  object             \n",
      " 2   vader_text     30615 non-null  object             \n",
      " 3   no_hashtags    30615 non-null  object             \n",
      " 4   full_clean     30615 non-null  object             \n",
      " 5   covid_mention  30615 non-null  int64              \n",
      " 6   retweet_count  30615 non-null  int64              \n",
      " 7   user_name      30615 non-null  object             \n",
      " 8   is_retweet     30615 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(3), object(5)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Create a new DatFrame with only original covid mentioning tweets\n",
    "# This will be used to guage the covids impact on sentiment\n",
    "\n",
    "df_no_rt_covid_mention = df_no_rt[df_no_rt['covid_mention'] == 1]\n",
    "df_no_rt_covid_mention.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293514"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total retweet count of all 384221 tweets\n",
    "\n",
    "raw.is_retweet.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118140"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimated total covid/pandemic mentions\n",
    "\n",
    "raw.covid_mention.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 399591 entries, 1294232573636304896 to 1329212767929200640\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype              \n",
      "---  ------         --------------   -----              \n",
      " 0   created_at     399591 non-null  datetime64[ns, UTC]\n",
      " 1   full_text      399591 non-null  object             \n",
      " 2   vader_text     399591 non-null  object             \n",
      " 3   no_hashtags    399591 non-null  object             \n",
      " 4   full_clean     399591 non-null  object             \n",
      " 5   covid_mention  399591 non-null  int64              \n",
      " 6   retweet_count  399591 non-null  int64              \n",
      " 7   user_name      399591 non-null  object             \n",
      " 8   is_retweet     399591 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(3), object(5)\n",
      "memory usage: 30.5+ MB\n"
     ]
    }
   ],
   "source": [
    "raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_rt_count = df_no_rt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated percentage of tweets related to #bcpoli that mention covid or the pandemic in some way: 28.86 %\n",
      "Total of 101569 original tweets related to #bcpoli that mention covid or the pandemic in some way: 30615\n"
     ]
    }
   ],
   "source": [
    "# Estimated total covid/pandemic mentions in 101569 original tweets\n",
    "\n",
    "no_rt_count = df_no_rt.shape[0]\n",
    "no_rt_covid_count = df_no_rt.covid_mention.sum()\n",
    "mention_ratio_no_rt = (no_rt_covid_count/no_rt_count) * 100\n",
    "\n",
    "print('Estimated percentage of tweets related to #bcpoli that mention covid or the pandemic in some way:', '%0.2f'% mention_ratio_no_rt,'%')\n",
    "print('Total of 101569 original tweets related to #bcpoli that mention covid or the pandemic in some way:', no_rt_covid_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(bc, liberals)            13170\n",
       "(john, horgan)            10070\n",
       "(bc, liberal)              9567\n",
       "(bonnie, henry)            9481\n",
       "(dr, bonnie)               8994\n",
       "(new, cases)               8608\n",
       "(british, columbians)      8291\n",
       "(british, columbia)        7433\n",
       "(bc, ndp)                  7159\n",
       "(andrew, wilkinson)        6915\n",
       "(dr, henry)                6103\n",
       "(site, c)                  3798\n",
       "(public, health)           3787\n",
       "(bc, election)             3667\n",
       "(henry, says)              3598\n",
       "(health, care)             3498\n",
       "(fraser, health)           3452\n",
       "(snap, election)           3407\n",
       "(physical, distancing)     3125\n",
       "(old, growth)              3025\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most frequent bigrams, hastags removed, stop words removed - Includes original tweets and retweets\n",
    "# This will be more interesting with data grouped by week\n",
    "\n",
    "top_ngrams(raw, n=2, ngrams=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(bc, liberals)            2481\n",
       "(bonnie, henry)           1888\n",
       "(dr, bonnie)              1860\n",
       "(bc, liberal)             1569\n",
       "(john, horgan)            1568\n",
       "(new, cases)              1546\n",
       "(bc, ndp)                 1507\n",
       "(dr, henry)               1413\n",
       "(british, columbians)     1230\n",
       "(british, columbia)       1127\n",
       "(andrew, wilkinson)       1058\n",
       "(bc, election)             917\n",
       "(snap, election)           871\n",
       "(public, health)           851\n",
       "(active, cases)            801\n",
       "(henry, says)              767\n",
       "(fraser, health)           659\n",
       "(health, care)             654\n",
       "(provincial, election)     627\n",
       "(old, growth)              615\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top bigrams from original tweets only\n",
    "\n",
    "top_ngrams(df_no_rt, n=2, ngrams=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(bc, liberals)            2290\n",
       "(bc, liberal)             1466\n",
       "(bc, ndp)                 1339\n",
       "(john, horgan)            1204\n",
       "(andrew, wilkinson)        963\n",
       "(british, columbians)      902\n",
       "(bc, election)             784\n",
       "(british, columbia)        751\n",
       "(old, growth)              603\n",
       "(provincial, election)     547\n",
       "(snap, election)           526\n",
       "(green, party)             523\n",
       "(bc, greens)               443\n",
       "(bc, green)                436\n",
       "(site, c)                  426\n",
       "(climate, change)          409\n",
       "(mental, health)           402\n",
       "(sign, petition)           399\n",
       "(growth, forests)          389\n",
       "(health, care)             389\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top bigrams from original tweets only, without covid mentioned\n",
    "# This is a good example of when stemming is benficial - See pluralized words below\n",
    "\n",
    "top_ngrams(df_no_rt_no_covid, n=2, ngrams=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dr, bonnie, henry)              8433\n",
       "(dr, henry, says)                2288\n",
       "(premier, john, horgan)          1895\n",
       "(bc, liberal, government)        1292\n",
       "(bc, liberal, party)             1244\n",
       "(bc, liberal, candidate)         1237\n",
       "(new, cases, covid19)            1199\n",
       "(old, growth, forests)           1122\n",
       "(breaking, dr, bonnie)           1102\n",
       "(leader, john, horgan)           1067\n",
       "(ndp, leader, john)              1022\n",
       "(deaths, far, year)              1015\n",
       "(british, columbia, deaths)      1013\n",
       "(coronavirus, 288, overdoses)    1011\n",
       "(columbia, deaths, far)          1011\n",
       "(288, overdoses, 1202)           1011\n",
       "(year, coronavirus, 288)         1011\n",
       "(far, year, coronavirus)         1011\n",
       "(new, covid19, cases)            1010\n",
       "(site, c, dam)                    933\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most frequent trigrams, hastags removed, stop words removed - Includes original tweets and retweets\n",
    "# This will be more interesting with data grouped by week\n",
    "\n",
    "top_ngrams(raw, n=3, ngrams=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dr, bonnie, henry)            1654\n",
       "(dr, henry, says)               420\n",
       "(old, growth, forests)          393\n",
       "(one, best, things)             338\n",
       "(protecting, old, growth)       337\n",
       "(sign, petition, protect)       334\n",
       "(last, giant, trees)            333\n",
       "(giant, trees, logging)         332\n",
       "(protect, last, giant)          332\n",
       "(things, mitigate, impacts)     332\n",
       "(petition, protect, last)       332\n",
       "(best, things, mitigate)        332\n",
       "(impacts, sign, petition)       331\n",
       "(mitigate, impacts, sign)       331\n",
       "(forests, one, best)            331\n",
       "(growth, forests, one)          327\n",
       "(bc, liberal, party)            284\n",
       "(going, back, school)           263\n",
       "(back, school, september)       247\n",
       "(everyone, going, back)         246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top trigrams from original tweets only\n",
    "\n",
    "top_ngrams(df_no_rt, n=3, ngrams=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(old, growth, forests)         389\n",
       "(protecting, old, growth)      337\n",
       "(one, best, things)            336\n",
       "(sign, petition, protect)      334\n",
       "(last, giant, trees)           333\n",
       "(petition, protect, last)      332\n",
       "(giant, trees, logging)        332\n",
       "(protect, last, giant)         332\n",
       "(best, things, mitigate)       332\n",
       "(things, mitigate, impacts)    332\n",
       "(forests, one, best)           331\n",
       "(impacts, sign, petition)      331\n",
       "(mitigate, impacts, sign)      331\n",
       "(growth, forests, one)         327\n",
       "(bc, liberal, party)           271\n",
       "(bc, green, party)             238\n",
       "(bc, liberal, leader)          192\n",
       "(leader, andrew, wilkinson)    179\n",
       "(bc, liberal, candidate)       172\n",
       "(premier, john, horgan)        152\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top trigrams from original tweets only, without covid mentioned\n",
    "# This is a good example of when stemming is benficial - See pluralized words below\n",
    "# Also a great example of why trigrams are useful - (old, growth)  (growth, forests)\n",
    "\n",
    "top_ngrams(df_no_rt_no_covid, n=3, ngrams=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle DataFrames for later use\n",
    "\n",
    "#df_no_rt.to_pickle('/Users/lclark/data_bootcamp/data-science-final-project/data/df_original_tweets.pkl')\n",
    "\n",
    "#df_no_rt_covid_mention.to_pickle('/Users/lclark/data_bootcamp/data-science-final-project/data/df_original_tweets_covid_mention.pkl')\n",
    "\n",
    "#df_no_rt_no_covid.to_pickle('/Users/lclark/data_bootcamp/data-science-final-project/data/df_original_tweets_no_covid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_bootcamp",
   "language": "python",
   "name": "data_bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
