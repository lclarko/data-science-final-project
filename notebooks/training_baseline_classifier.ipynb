{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Sentiment Classifier\n",
    "* This notebook will be used to train and evaluate several sentiment classifiers.\n",
    "* Models in this notebook will serve as a baseline\n",
    "* The [SemEval-2017 gold dataset](https://alt.qcri.org/semeval2017/task4/?id=download-the-full-training-data-for-semeval-2017-task-4) was combined with additional positive and negative tweets, dictacted by the presence of :) or :(\n",
    " * The decision to add the recent :) and :( tweets to the classifier training dataset is to include tweets the mention Covid-19. The SemEval-2017 dataset existed long before Covid-19 came into our world. \n",
    "* Depending on the performance of VADER in classifies the tweets in this novel datset, an LSTM may later be trained and used for classifying s tream of tweets, outside the scope of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import re\n",
    "import string\n",
    "from glob import glob\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all TSVs from SemEval-2017\n",
    "\n",
    "data_1 = '.csv'\n",
    "column_names = ['ids', 'target', 'text']\n",
    "\n",
    "gold_tweets = pd.DataFrame()\n",
    "names = ['ids', 'target', 'text']\n",
    "\n",
    "for f in glob('*.txt'):\n",
    "    tmp = pd.read_csv(f,names=names, sep='\\t')\n",
    "\n",
    "    gold_tweets = pd.concat([gold_tweets,tmp],axis=0,ignore_index=True)\n",
    "    \n",
    "gold_tweets['text'] = gold_tweets['text'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sad Tweets Shape (49912, 3)\n",
      "New Shape (99592, 3)\n",
      "Training Data:\n",
      " negative    57655\n",
      "neutral     22271\n",
      "positive    19629\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add collected sad tweets to human labeled tweet dataset\n",
    "# This cell an be excluded, if desired\n",
    "\n",
    "sad_tweets_buffer = pd.read_pickle('sad_tweets_buffer.pkl')\n",
    "\n",
    "sad_tweets_buffer = sad_tweets_buffer[['id','processed_features','target']].copy()\n",
    "sad_tweets_buffer.rename(columns={\"id\": \"ids\", \"processed_features\": \"text\"}, inplace=True)\n",
    "sad_tweets_buffer.reset_index(inplace=True, drop=True)\n",
    "sad_tweets_buffer['target'] = 'negative'\n",
    "print('Sad Tweets Shape',sad_tweets_buffer.shape)\n",
    "\n",
    "gold_tweets = pd.concat([gold_tweets,sad_tweets_buffer],axis=0,ignore_index=True)\n",
    "gold_tweets.target.value_counts()\n",
    "print('New Shape',gold_tweets.shape)\n",
    "print('Training Data:\\n', gold_tweets.target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy Tweets Shape (38026, 3)\n",
      "New Shape (137618, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "negative    57655\n",
       "positive    57655\n",
       "neutral     22271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add collected happy tweets to human labeled tweet dataset\n",
    "# This cell an be excluded, if desired\n",
    "\n",
    "happy_tweets_buffer = pd.read_pickle('happy_tweets_buffer.pkl')\n",
    "\n",
    "happy_tweets_buffer = happy_tweets_buffer[['id','text','target']].copy()\n",
    "happy_tweets_buffer.rename(columns={\"id\": \"ids\"}, inplace=True)\n",
    "happy_tweets_buffer.reset_index(inplace=True, drop=True)\n",
    "print('Happy Tweets Shape',happy_tweets_buffer.shape)\n",
    "\n",
    "gold_tweets = pd.concat([gold_tweets,happy_tweets_buffer],axis=0,ignore_index=True)\n",
    "gold_tweets.target.value_counts()\n",
    "print('New Shape',gold_tweets.shape)\n",
    "gold_tweets.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    57655\n",
       "positive    57655\n",
       "neutral     44542\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doubling down on the exiting neutral tweets to attempt handle the imbalance\n",
    "# Comment out to skip and everything below will still work\n",
    "\n",
    "# ** This will have a direct impact on and improve the train test scores of the models below, specifically the F1 score for neutral tweets and weighted avg compound F1 **\n",
    "# ** This is a heuristic approach that has resulted in the improved generalization of the baseline classification model on new, unseen tweets **\n",
    "# ** VADER compound scores will be used in the classification of the full twitter dataset and compared to our baseline models **\n",
    "\n",
    "gold_temp = gold_tweets.copy()\n",
    "neutral_tweets = gold_temp[gold_temp.values  == \"neutral\"]\n",
    "neutral_tweets = neutral_tweets[['ids','text','target']]\n",
    "gold_tweets = pd.concat([gold_tweets,neutral_tweets],axis=0,ignore_index=True)\n",
    "\n",
    "# Set Index and display distribution \n",
    "gold_tweets.set_index('ids', inplace=True)\n",
    "gold_tweets.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    57655\n",
       "0    57655\n",
       "2    44579\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encode the tweet sentiments\n",
    "\n",
    "def binarizer(x):\n",
    "    if x == 'positive':\n",
    "        return 4\n",
    "    elif x == 'negative':\n",
    "        return 0 \n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "gold_tweets['labels'] = gold_tweets['target'].apply(lambda x: binarizer(x))\n",
    "gold_tweets.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ASCII based emotions to \"emoneg\" and \"emopos\".\n",
    "# This function now lives in functions.py\n",
    "\n",
    "def emoji_stringer(text):\n",
    "    # Positive Emoji - Smile, Laugh, Wink,Love\n",
    "    text = ' '.join(re.sub('(:\\s?\\)|:-\\)|;\\)|\\(\\s?:|\\(-:|:\\’\\))','emopos',text).split()) # add this :-))\n",
    "    text = ' '.join(re.sub('(:\\s?D|:-D|x-?D|X-?D)','emopos',text).split()) \n",
    "    text = ' '.join(re.sub('(<3|:\\*)','emopos',text).split()) \n",
    "    # Negative Emoji - Sad, Cry\n",
    "    text = ' '.join(re.sub('(:\\s?\\(|:-\\(|:\\||\\)\\s?:|\\)-:)','emoneg',text).split())\n",
    "    text = ' '.join(re.sub('(:,\\(|:\\’\\(|:\"\\()','emoneg',text).split())\n",
    "    return text\n",
    "\n",
    "gold_tweets['text']=gold_tweets['text'].apply(str)\n",
    "gold_tweets['emo_features'] = gold_tweets['text'].apply(lambda x: emoji_stringer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>emo_features</th>\n",
       "      <th>full_text_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ids</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>628949369883000832</th>\n",
       "      <td>negative</td>\n",
       "      <td>dear @Microsoft the newOoffice for Mac is great and all, but no Lync update? C'mon.</td>\n",
       "      <td>0</td>\n",
       "      <td>dear @Microsoft the newOoffice for Mac is great and all, but no Lync update? C'mon.</td>\n",
       "      <td>dear USER the newooffice for mac is great and all, but no lync update? c'mon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628976607420645377</th>\n",
       "      <td>negative</td>\n",
       "      <td>@Microsoft how about you make a system that doesn't eat my friggin discs. This is the 2nd time this has happened and I am so sick of it!</td>\n",
       "      <td>0</td>\n",
       "      <td>@Microsoft how about you make a system that doesn't eat my friggin discs. This is the 2nd time this has happened and I am so sick of it!</td>\n",
       "      <td>USER how about you make a system that doesn't eat my friggin discs. this is the 2nd time this has happened and i am so sick of it!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629023169169518592</th>\n",
       "      <td>negative</td>\n",
       "      <td>I may be ignorant on this issue but... should we celebrate @Microsoft's parental leave changes? Doesn't the gender divide suggest... (1/2)</td>\n",
       "      <td>0</td>\n",
       "      <td>I may be ignorant on this issue but... should we celebrate @Microsoft's parental leave changes? Doesn't the gender divide suggest... (1/2)</td>\n",
       "      <td>i may be ignorant on this issue but... should we celebrate USER 's parental leave changes? doesn't the gender divide suggest... (1/2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629179223232479232</th>\n",
       "      <td>negative</td>\n",
       "      <td>Thanks to @microsoft, I just may be switching over to @apple.</td>\n",
       "      <td>0</td>\n",
       "      <td>Thanks to @microsoft, I just may be switching over to @apple.</td>\n",
       "      <td>thanks to USER , i just may be switching over to USER .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629186282179153920</th>\n",
       "      <td>neutral</td>\n",
       "      <td>If I make a game as a #windows10 Universal App. Will #xboxone owners be able to download and play it in November? @majornelson @Microsoft</td>\n",
       "      <td>2</td>\n",
       "      <td>If I make a game as a #windows10 Universal App. Will #xboxone owners be able to download and play it in November? @majornelson @Microsoft</td>\n",
       "      <td>if i make a game as a #windows10 universal app. will #xboxone owners be able to download and play it in november? USER USER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629226490152914944</th>\n",
       "      <td>positive</td>\n",
       "      <td>Microsoft, I may not prefer your gaming branch of business. But, you do make a damn fine operating system. #Windows10 @Microsoft</td>\n",
       "      <td>4</td>\n",
       "      <td>Microsoft, I may not prefer your gaming branch of business. But, you do make a damn fine operating system. #Windows10 @Microsoft</td>\n",
       "      <td>microsoft, i may not prefer your gaming branch of business. but, you do make a damn fine operating system. #windows10 USER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629345637155360768</th>\n",
       "      <td>negative</td>\n",
       "      <td>@MikeWolf1980 @Microsoft I will be downgrading and let #Windows10 be out for almost the 1st yr b4 trying it again. #Windows10fail</td>\n",
       "      <td>0</td>\n",
       "      <td>@MikeWolf1980 @Microsoft I will be downgrading and let #Windows10 be out for almost the 1st yr b4 trying it again. #Windows10fail</td>\n",
       "      <td>USER USER i will be downgrading and let #windows10 be out for almost the 1st yr b4 trying it again. #windows10fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629394528336637953</th>\n",
       "      <td>negative</td>\n",
       "      <td>@Microsoft 2nd computer with same error!!! #Windows10fail Guess we will shelve this until SP1! http://t.co/QCcHlKuy8Q</td>\n",
       "      <td>0</td>\n",
       "      <td>@Microsoft 2nd computer with same error!!! #Windows10fail Guess we will shelve this until SP1! http://t.co/QCcHlKuy8Q</td>\n",
       "      <td>USER 2nd computer with same error!!! #windows10fail guess we will shelve this until sp1! URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629650766580609026</th>\n",
       "      <td>positive</td>\n",
       "      <td>Just ordered my 1st ever tablet; @Microsoft Surface Pro 3, i7/8GB 512GB SSD. Hopefully it works out for dev to replace my laptop =)</td>\n",
       "      <td>4</td>\n",
       "      <td>Just ordered my 1st ever tablet; @Microsoft Surface Pro 3, i7/8GB 512GB SSD. Hopefully it works out for dev to replace my laptop =)</td>\n",
       "      <td>just ordered my 1st ever tablet; USER surface pro 3, i7/8gb 512gb ssd. hopefully it works out for dev to replace my laptop =)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629797991826722816</th>\n",
       "      <td>negative</td>\n",
       "      <td>After attempting a reinstall, it still bricks, says, \"Windows cannot finish installing,\" or somesuch. @Microsoft may have cost me $600.</td>\n",
       "      <td>0</td>\n",
       "      <td>After attempting a reinstall, it still bricks, says, \"Windows cannot finish installing,\" or somesuch. @Microsoft may have cost me $600.</td>\n",
       "      <td>after attempting a reinstall, it still bricks, says, \"windows cannot finish installing,\" or somesuch. USER may have cost me $600.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      target  \\\n",
       "ids                            \n",
       "628949369883000832  negative   \n",
       "628976607420645377  negative   \n",
       "629023169169518592  negative   \n",
       "629179223232479232  negative   \n",
       "629186282179153920   neutral   \n",
       "629226490152914944  positive   \n",
       "629345637155360768  negative   \n",
       "629394528336637953  negative   \n",
       "629650766580609026  positive   \n",
       "629797991826722816  negative   \n",
       "\n",
       "                                                                                                                                                          text  \\\n",
       "ids                                                                                                                                                              \n",
       "628949369883000832                                                         dear @Microsoft the newOoffice for Mac is great and all, but no Lync update? C'mon.   \n",
       "628976607420645377    @Microsoft how about you make a system that doesn't eat my friggin discs. This is the 2nd time this has happened and I am so sick of it!   \n",
       "629023169169518592  I may be ignorant on this issue but... should we celebrate @Microsoft's parental leave changes? Doesn't the gender divide suggest... (1/2)   \n",
       "629179223232479232                                                                               Thanks to @microsoft, I just may be switching over to @apple.   \n",
       "629186282179153920   If I make a game as a #windows10 Universal App. Will #xboxone owners be able to download and play it in November? @majornelson @Microsoft   \n",
       "629226490152914944            Microsoft, I may not prefer your gaming branch of business. But, you do make a damn fine operating system. #Windows10 @Microsoft   \n",
       "629345637155360768           @MikeWolf1980 @Microsoft I will be downgrading and let #Windows10 be out for almost the 1st yr b4 trying it again. #Windows10fail   \n",
       "629394528336637953                       @Microsoft 2nd computer with same error!!! #Windows10fail Guess we will shelve this until SP1! http://t.co/QCcHlKuy8Q   \n",
       "629650766580609026         Just ordered my 1st ever tablet; @Microsoft Surface Pro 3, i7/8GB 512GB SSD. Hopefully it works out for dev to replace my laptop =)   \n",
       "629797991826722816     After attempting a reinstall, it still bricks, says, \"Windows cannot finish installing,\" or somesuch. @Microsoft may have cost me $600.   \n",
       "\n",
       "                    labels  \\\n",
       "ids                          \n",
       "628949369883000832       0   \n",
       "628976607420645377       0   \n",
       "629023169169518592       0   \n",
       "629179223232479232       0   \n",
       "629186282179153920       2   \n",
       "629226490152914944       4   \n",
       "629345637155360768       0   \n",
       "629394528336637953       0   \n",
       "629650766580609026       4   \n",
       "629797991826722816       0   \n",
       "\n",
       "                                                                                                                                                  emo_features  \\\n",
       "ids                                                                                                                                                              \n",
       "628949369883000832                                                         dear @Microsoft the newOoffice for Mac is great and all, but no Lync update? C'mon.   \n",
       "628976607420645377    @Microsoft how about you make a system that doesn't eat my friggin discs. This is the 2nd time this has happened and I am so sick of it!   \n",
       "629023169169518592  I may be ignorant on this issue but... should we celebrate @Microsoft's parental leave changes? Doesn't the gender divide suggest... (1/2)   \n",
       "629179223232479232                                                                               Thanks to @microsoft, I just may be switching over to @apple.   \n",
       "629186282179153920   If I make a game as a #windows10 Universal App. Will #xboxone owners be able to download and play it in November? @majornelson @Microsoft   \n",
       "629226490152914944            Microsoft, I may not prefer your gaming branch of business. But, you do make a damn fine operating system. #Windows10 @Microsoft   \n",
       "629345637155360768           @MikeWolf1980 @Microsoft I will be downgrading and let #Windows10 be out for almost the 1st yr b4 trying it again. #Windows10fail   \n",
       "629394528336637953                       @Microsoft 2nd computer with same error!!! #Windows10fail Guess we will shelve this until SP1! http://t.co/QCcHlKuy8Q   \n",
       "629650766580609026         Just ordered my 1st ever tablet; @Microsoft Surface Pro 3, i7/8GB 512GB SSD. Hopefully it works out for dev to replace my laptop =)   \n",
       "629797991826722816     After attempting a reinstall, it still bricks, says, \"Windows cannot finish installing,\" or somesuch. @Microsoft may have cost me $600.   \n",
       "\n",
       "                                                                                                                                          full_text_clean  \n",
       "ids                                                                                                                                                        \n",
       "628949369883000832                                                          dear USER the newooffice for mac is great and all, but no lync update? c'mon.  \n",
       "628976607420645377     USER how about you make a system that doesn't eat my friggin discs. this is the 2nd time this has happened and i am so sick of it!  \n",
       "629023169169518592  i may be ignorant on this issue but... should we celebrate USER 's parental leave changes? doesn't the gender divide suggest... (1/2)  \n",
       "629179223232479232                                                                                thanks to USER , i just may be switching over to USER .  \n",
       "629186282179153920            if i make a game as a #windows10 universal app. will #xboxone owners be able to download and play it in november? USER USER  \n",
       "629226490152914944             microsoft, i may not prefer your gaming branch of business. but, you do make a damn fine operating system. #windows10 USER  \n",
       "629345637155360768                     USER USER i will be downgrading and let #windows10 be out for almost the 1st yr b4 trying it again. #windows10fail  \n",
       "629394528336637953                                           USER 2nd computer with same error!!! #windows10fail guess we will shelve this until sp1! URL  \n",
       "629650766580609026          just ordered my 1st ever tablet; USER surface pro 3, i7/8gb 512gb ssd. hopefully it works out for dev to replace my laptop =)  \n",
       "629797991826722816      after attempting a reinstall, it still bricks, says, \"windows cannot finish installing,\" or somesuch. USER may have cost me $600.  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess Tweets - lowercase, URLS, tokens and punctuation\n",
    "# An improved version of this function now lives in functions.py\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower() # Vader considers case\n",
    "    text = ' '.join(re.sub(\"((www\\.[\\S]+)|(https?://[\\S]+))\",\"URL\",text).split())\n",
    "    text = ' '.join(re.sub(\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)\",\"USER \",text).split())\n",
    "    #text = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]|(\\w+:\\/\\/\\S+))\",\"USER \",text).split())\n",
    "    text = ' '.join(re.sub(\"^rt\",\"\",text).split())\n",
    "    #punc = ''.join([char for char in text if char not in string.punctuation])\n",
    "    #tokens = word_tokenize(text)\n",
    "    #stops = [word for word in tokens if word not in stop_words]\n",
    "    #strings = (\" \").join(stops)\n",
    "    return text\n",
    "\n",
    "gold_tweets['full_text_clean'] = gold_tweets['emo_features'].apply(lambda x: preprocess(x))\n",
    "gold_tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_tweets.labels.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 159889 entries, 628949369883000832 to 641395811474128896\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   target           159852 non-null  object\n",
      " 1   text             159889 non-null  object\n",
      " 2   labels           159889 non-null  int64 \n",
      " 3   emo_features     159889 non-null  object\n",
      " 4   full_text_clean  159889 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "gold_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backing up combined tweets\n",
    "#gold_tweets.to_pickle('combined_train_tweets157k.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159889,)\n",
      "(159889, 40000)\n"
     ]
    }
   ],
   "source": [
    "# Create vector representations of the tweets to then use in model. \n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True, lowercase=True, ngram_range=(1,2), max_features=40000) # 40k may be too high a feature count and cause unecessary computational use when padding future vectorizations\n",
    "\n",
    "y = gold_tweets.labels\n",
    "X = vectorizer.fit_transform(gold_tweets.full_text_clean)\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logreg = LogisticRegression(n_jobs=-1)\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "\n",
    "# Random Forest was also test and demonstrated poor performance value when compared to Logisitic Regression, and of course Naive Bayes Multinomial. (>10x training time of LogReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.7 ms, sys: 4.49 ms, total: 46.1 ms\n",
      "Wall time: 44.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 73.9 ms, sys: 138 ms, total: 212 ms\n",
      "Wall time: 7.56 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(n_jobs=-1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Vanilla LogReg\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 16.3min finished\n",
      "/anaconda3/envs/data_bootcamp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 4.63 s, total: 1min 22s\n",
      "Wall time: 16min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Grid Search\n",
    "\n",
    "pipe = Pipeline([('classifier', LogisticRegression(n_jobs=-1))])\n",
    "\n",
    "# Create param grid\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression(n_jobs=-1)],\n",
    "     'classifier__penalty' : ['l1', 'l2'], # lbfgs only supports l2 - Separate solvers into two groups inside grid to resolve warnings\n",
    "     'classifier__C' : np.logspace(-4, 4, 20),\n",
    "     'classifier__solver' : ['lbfgs','liblinear']}\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 11.288378916846883,\n",
       " 'classifier__penalty': 'l1',\n",
       " 'classifier__solver': 'liblinear'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_grid_pred = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Including Oversampled Neutral Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Reg CLF Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92     11541\n",
      "           2       0.75      0.90      0.82      8812\n",
      "           4       0.90      0.83      0.86     11625\n",
      "\n",
      "    accuracy                           0.87     31978\n",
      "   macro avg       0.87      0.87      0.87     31978\n",
      "weighted avg       0.88      0.87      0.87     31978\n",
      "\n",
      "-----------------------------------------------------------\n",
      "NB Multi CLF Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.82      0.89     11541\n",
      "           2       0.68      0.91      0.78      8812\n",
      "           4       0.86      0.78      0.81     11625\n",
      "\n",
      "    accuracy                           0.83     31978\n",
      "   macro avg       0.84      0.84      0.83     31978\n",
      "weighted avg       0.85      0.83      0.83     31978\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Log Reg GridCV CLF Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92     11541\n",
      "           2       0.80      0.92      0.86      8812\n",
      "           4       0.91      0.85      0.88     11625\n",
      "\n",
      "    accuracy                           0.89     31978\n",
      "   macro avg       0.89      0.89      0.89     31978\n",
      "weighted avg       0.89      0.89      0.89     31978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With emoneg and emopos\n",
    "# With added 50k happy and sad face tweets and doubled exisiting neutral\n",
    "\n",
    "print('Log Reg CLF Report')\n",
    "print(classification_report(y_test, logreg_pred))\n",
    "print('-----------------------------------------------------------')\n",
    "print('NB Multi CLF Report')\n",
    "print(classification_report(y_test, nb_pred))\n",
    "print('-----------------------------------------------------------')\n",
    "print('Log Reg GridCV CLF Report')\n",
    "print(classification_report(y_test, logreg_grid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9527 1305  709]\n",
      " [  40 8052  720]\n",
      " [ 203 2414 9008]]\n"
     ]
    }
   ],
   "source": [
    "# With emoneg and emopos\n",
    "# With added 50k happy and sad face tweets and doubled exisiting neutral\n",
    "\n",
    "cm_nb = confusion_matrix(y_test,nb_pred)\n",
    "print(cm_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10274   972   295]\n",
      " [  178  7951   683]\n",
      " [  225  1781  9619]]\n"
     ]
    }
   ],
   "source": [
    "# With emoneg and emopos\n",
    "# With added 50k happy and sad face tweets and doubled exisiting neutral\n",
    "\n",
    "cm_lr = confusion_matrix(y_test,logreg_pred)\n",
    "print(cm_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10421   707   413]\n",
      " [  173  8155   484]\n",
      " [  395  1396  9834]]\n"
     ]
    }
   ],
   "source": [
    "# With emoneg and emopos\n",
    "# With added 50k happy and sad face tweets and doubled exisiting neutral\n",
    "\n",
    "cm_lrg = confusion_matrix(y_test,logreg_grid_pred)\n",
    "print(cm_lrg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Tuned Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'tweet_40kfeat_LR_GridCV_3C_89p_model.sav'\n",
    "#pickle.dump(best_clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Not Including Oversampled Neutral Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Reg CLF Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92     11459\n",
      "           2       0.64      0.69      0.66      4560\n",
      "           4       0.87      0.88      0.87     11505\n",
      "\n",
      "    accuracy                           0.86     27524\n",
      "   macro avg       0.82      0.82      0.82     27524\n",
      "weighted avg       0.86      0.86      0.86     27524\n",
      "\n",
      "-----------------------------------------------------------\n",
      "NB Multi CLF Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.83      0.89     11459\n",
      "           2       0.59      0.65      0.62      4560\n",
      "           4       0.78      0.87      0.83     11505\n",
      "\n",
      "    accuracy                           0.82     27524\n",
      "   macro avg       0.78      0.78      0.78     27524\n",
      "weighted avg       0.83      0.82      0.82     27524\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Log Reg GridCV CLF Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92     11459\n",
      "           2       0.64      0.71      0.67      4560\n",
      "           4       0.88      0.87      0.87     11505\n",
      "\n",
      "    accuracy                           0.86     27524\n",
      "   macro avg       0.82      0.83      0.82     27524\n",
      "weighted avg       0.86      0.86      0.86     27524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With emoneg and emopos\n",
    "# With added 50k happy and sad face tweets\n",
    "# WITHOUT oversampled neutral tweets\n",
    "\n",
    "print('Log Reg CLF Report')\n",
    "print(classification_report(y_test, logreg_pred))\n",
    "print('-----------------------------------------------------------')\n",
    "print('NB Multi CLF Report')\n",
    "print(classification_report(y_test, nb_pred))\n",
    "print('-----------------------------------------------------------')\n",
    "print('Log Reg GridCV CLF Report')\n",
    "print(classification_report(y_test, logreg_grid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9485   778  1196]\n",
      " [   50  2948  1562]\n",
      " [  206  1263 10036]]\n"
     ]
    }
   ],
   "source": [
    "# With emoneg and emopos\n",
    "# With added 50k happy and sad face tweets \n",
    "# WITHOUT oversampled neutral tweets\n",
    "\n",
    "cm_nb_no_os = confusion_matrix(y_test,nb_pred)\n",
    "print(cm_nb_no_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10370   645   444]\n",
      " [  332  3128  1100]\n",
      " [  276  1121 10108]]\n"
     ]
    }
   ],
   "source": [
    "# With emoneg and emopos\n",
    "# With added 50k happy and sad face tweets\n",
    "# WITHOUT oversampled neutral tweets\n",
    "\n",
    "cm_lr_no_os = confusion_matrix(y_test,logreg_pred)\n",
    "print(cm_lr_no_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10380   657   422]\n",
      " [  338  3225   997]\n",
      " [  311  1145 10049]]\n"
     ]
    }
   ],
   "source": [
    "# With emoneg and emopos\n",
    "# With added 50k happy and sad face tweets\n",
    "# WITHOUT oversampled neutral tweets\n",
    "\n",
    "cm_lrg_no_os = confusion_matrix(y_test,logreg_grid_pred)\n",
    "print(cm_lrg_no_os)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_bootcamp",
   "language": "python",
   "name": "data_bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
