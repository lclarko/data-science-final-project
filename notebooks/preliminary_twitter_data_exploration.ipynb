{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Data - Exploring a Sample of 160k Tweets\n",
    "\n",
    "* The purpose of this notebook is to take a glance at sample of the collected twitter data.\n",
    "* Minimal text processing will take place here.\n",
    "* Columns not required for analysis will be dropped here.\n",
    " * The remaining data will be exported for preprocessing in \"classify_unlabelled_tweets.ipynb\"\n",
    "* The full ~400K tweet dataset will be processed in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from IPython.display import JSON\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Pandas Display Settings, if you wish\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#pd.set_option(\"display.max_columns\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 164K Tweets - August 14th, 2020 - October 1, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/Volumes/My Passport/Tweets/bc_tweets.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164548 entries, 0 to 164547\n",
      "Data columns (total 31 columns):\n",
      " #   Column                     Non-Null Count   Dtype              \n",
      "---  ------                     --------------   -----              \n",
      " 0   created_at                 164548 non-null  datetime64[ns, UTC]\n",
      " 1   id                         164548 non-null  int64              \n",
      " 2   id_str                     164548 non-null  int64              \n",
      " 3   full_text                  164548 non-null  object             \n",
      " 4   truncated                  164548 non-null  bool               \n",
      " 5   display_text_range         164548 non-null  object             \n",
      " 6   entities                   164548 non-null  object             \n",
      " 7   source                     164548 non-null  object             \n",
      " 8   in_reply_to_status_id      11682 non-null   float64            \n",
      " 9   in_reply_to_status_id_str  11682 non-null   float64            \n",
      " 10  in_reply_to_user_id        12791 non-null   float64            \n",
      " 11  in_reply_to_user_id_str    12791 non-null   float64            \n",
      " 12  in_reply_to_screen_name    12791 non-null   object             \n",
      " 13  user                       164548 non-null  object             \n",
      " 14  geo                        8 non-null       object             \n",
      " 15  coordinates                8 non-null       object             \n",
      " 16  place                      1443 non-null    object             \n",
      " 17  contributors               0 non-null       float64            \n",
      " 18  retweeted_status           121588 non-null  object             \n",
      " 19  is_quote_status            164548 non-null  bool               \n",
      " 20  quoted_status_id           38073 non-null   float64            \n",
      " 21  quoted_status_id_str       38073 non-null   float64            \n",
      " 22  quoted_status_permalink    38073 non-null   object             \n",
      " 23  retweet_count              164548 non-null  int64              \n",
      " 24  favorite_count             164548 non-null  int64              \n",
      " 25  favorited                  164548 non-null  bool               \n",
      " 26  retweeted                  164548 non-null  bool               \n",
      " 27  lang                       164548 non-null  object             \n",
      " 28  quoted_status              11311 non-null   object             \n",
      " 29  possibly_sensitive         36369 non-null   float64            \n",
      " 30  extended_entities          8531 non-null    object             \n",
      "dtypes: bool(4), datetime64[ns, UTC](1), float64(8), int64(4), object(14)\n",
      "memory usage: 34.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of imported data and set index to unique tweet ID\n",
    "\n",
    "raw = df.copy()\n",
    "raw.set_index('id_str', inplace=True)\n",
    "\n",
    "# Filter out columns\n",
    "\n",
    "raw = raw[['created_at','user','full_text','retweet_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from user column dict with .get\n",
    "\n",
    "raw['user_name'] = raw['user'].apply(lambda x: x.get('screen_name'))\n",
    "\n",
    "# Drop user column\n",
    "\n",
    "raw.drop('user', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is covid or anything pandemic related mentioned in the tweet?\n",
    "\n",
    "# All lowercase*\n",
    "# This list of terms may be expanded.\n",
    "covid_list = ['covid','virus', 'corona','ncov','sars', 'super spread', 'super-spread', 'pandemic', 'epidemic', 'outbreak', 'new case', 'new death', 'active case', 'community spread', 'contact trac', 'social distanc','self isolat', 'self-isolat', 'mask', 'ppe', 'quarantine', 'lockdown', 'symptomatic', 'vaccine', 'bonnie']\n",
    "\n",
    "# For tweet, if any term in covid_list is present in tweet, return 1. If not, return 0\n",
    "def covid_mention(text, synonyms=covid_list):\n",
    "    for term in synonyms:\n",
    "        if term in text:\n",
    "            return 1\n",
    "        continue\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary column for is_retweet\n",
    "\n",
    "rt_regex = \"^rt\"\n",
    "\n",
    "def is_retweet(text):\n",
    "    if re.match(rt_regex, text) is not None:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most common n-grams\n",
    "## Remove stop words, URLs, usernames and punctuation. I am considering leaving the plain text usernames\n",
    "\n",
    "def preprocess(text, hashtags=False, join=False):\n",
    "    text = text.lower()\n",
    "    if hashtags:\n",
    "        text = ' '.join(re.sub(r\"\\#\\w*[a-zA-Z]+\\w*\",\"\",text).split())\n",
    "    text = ' '.join(re.sub(\"((www\\.[\\S]+)|(https?://[\\S]+))\",\"\",text).split())\n",
    "    text = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\"\",text).split())\n",
    "    text = ' '.join(re.sub(\"^\\n\",\"\",text).split())\n",
    "    text = ' '.join(re.sub(\"^rt\",\"\",text).split())\n",
    "    punc = ''.join([char for char in text if char not in string.punctuation])\n",
    "    tokens = word_tokenize(punc)\n",
    "    stops = [word for word in tokens if word not in stop_words]\n",
    "    if join:\n",
    "        stops = (' ').join(stops)\n",
    "    return stops\n",
    "\n",
    "# Join Tokenized strings\n",
    "\n",
    "def joiner(text):\n",
    "    string = (' ').join(text)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove case sensitivity\n",
    "\n",
    "raw[\"full_text\"] = raw[\"full_text\"].str.lower()\n",
    "\n",
    "# Create binary column for covid_mention\n",
    "\n",
    "raw['covid_mention'] = raw['full_text'].apply(covid_mention)\n",
    "\n",
    "# Create binary column for is_retweet\n",
    "raw['is_retweet'] = raw['full_text'].apply(is_retweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all the tweets\n",
    "raw['full_clean'] = raw['full_text'].apply(preprocess)\n",
    "\n",
    "# Create column without hastags\n",
    "raw['no_hashtags'] = raw['full_text'].apply(lambda x: preprocess(x, hashtags=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Mentions of Covid-19 or the Pandemic in 164K Tweets: 33937\n"
     ]
    }
   ],
   "source": [
    "print('Estimated Mentions of Covid-19 or the Pandemic in 164K Tweets:', raw.covid_mention.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(bced, bcpoli)           5682\n",
       "(cdnpoli, bcpoli)        5387\n",
       "(john, horgan)           3924\n",
       "(bcpoli, cdnpoli)        3683\n",
       "(bc, liberals)           3567\n",
       "(bonnie, henry)          3503\n",
       "(dr, bonnie)             3241\n",
       "(new, cases)             3082\n",
       "(dr, henry)              2562\n",
       "(bcpoli, bcelxn2020)     2529\n",
       "(british, columbians)    2186\n",
       "(bc, liberal)            2120\n",
       "(bcpoli, bc)             2094\n",
       "(bcpoli, covid19)        2061\n",
       "(covid19, cases)         1888\n",
       "(bc, ndp)                1723\n",
       "(breaking, bc)           1619\n",
       "(bcpoli, bced)           1591\n",
       "(bcpoli, vanpoli)        1588\n",
       "(henry, says)            1578\n",
       "dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most frequent bigrams - Hashtags included, stop words removed\n",
    "\n",
    "words = preprocess(''.join(str(raw['full_clean'].tolist())))\n",
    "(pd.Series(nltk.ngrams(words, 2)).value_counts())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(john, horgan)           3924\n",
       "(bc, liberals)           3568\n",
       "(bonnie, henry)          3500\n",
       "(new, cases)             3329\n",
       "(dr, bonnie)             3239\n",
       "(dr, henry)              2562\n",
       "(british, columbians)    2187\n",
       "(bc, liberal)            2116\n",
       "(bc, ndp)                1726\n",
       "(henry, says)            1579\n",
       "(snap, election)         1512\n",
       "(andrew, wilkinson)      1505\n",
       "(british, columbia)      1482\n",
       "(back, school)           1258\n",
       "(banquet, halls)         1225\n",
       "(active, cases)          1209\n",
       "(public, health)         1135\n",
       "(breaking, dr)           1056\n",
       "(fall, election)         1054\n",
       "(premier, john)          1036\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most frequent bigrams, hastags removed, stop words removed\n",
    "\n",
    "words_no_ht = preprocess(''.join(str(raw['no_hashtags'].tolist())))\n",
    "(pd.Series(nltk.ngrams(words_no_ht, 2)).value_counts())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(bc,)            39293\n",
       "(election,)      15240\n",
       "(new,)           13075\n",
       "(amp,)           12859\n",
       "(cases,)         11342\n",
       "(people,)         9795\n",
       "(government,)     8493\n",
       "(says,)           8447\n",
       "(school,)         8382\n",
       "(ndp,)            8237\n",
       "(health,)         8232\n",
       "(horgan,)         8117\n",
       "(one,)            7573\n",
       "(time,)           6756\n",
       "(henry,)          6719\n",
       "(would,)          6587\n",
       "(schools,)        6582\n",
       "(dr,)             6561\n",
       "(need,)           6335\n",
       "(teachers,)       6271\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top individual terms\n",
    "(pd.Series(nltk.ngrams(words_no_ht, 1)).value_counts())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_bootcamp",
   "language": "python",
   "name": "data_bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
